{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/azmi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/azmi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/azmi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/azmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument \n",
    "from gensim.models import Word2Vec \n",
    "import nltk\n",
    "from scipy import spatial\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs=pd.read_csv(\"mozilla_firefox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_id</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Component</th>\n",
       "      <th>Duplicated_issue</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Version</th>\n",
       "      <th>Created_time</th>\n",
       "      <th>Resolved_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10954</td>\n",
       "      <td>P3</td>\n",
       "      <td>Preferences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dialup properties needs to be exposed in prefs</td>\n",
       "      <td>The dialup properties of the profile should be...</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>WONTFIX</td>\n",
       "      <td>Trunk</td>\n",
       "      <td>1999-07-30 15:55:51 -0700</td>\n",
       "      <td>2008-05-14 11:44:15 -0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14871</td>\n",
       "      <td>--</td>\n",
       "      <td>General</td>\n",
       "      <td>269442.0</td>\n",
       "      <td>[Find] Find whole word only</td>\n",
       "      <td>Please add Match Whole Word Only option to bro...</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>DUPLICATE</td>\n",
       "      <td>Trunk</td>\n",
       "      <td>1999-09-24 14:49:34 -0700</td>\n",
       "      <td>2011-10-05 16:35:31 -0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19118</td>\n",
       "      <td>--</td>\n",
       "      <td>Preferences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plug-In Manager (ui for choosing mimetype-plug...</td>\n",
       "      <td>I would really like a plug-in manager for my b...</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>WONTFIX</td>\n",
       "      <td>Trunk</td>\n",
       "      <td>1999-11-17 14:58:26 -0800</td>\n",
       "      <td>2013-01-29 11:48:39 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54746</td>\n",
       "      <td>P3</td>\n",
       "      <td>Preferences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language encodings in font prefs dialog not so...</td>\n",
       "      <td>Language encodings are listed in a seemingly r...</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>WORKSFORME</td>\n",
       "      <td>Trunk</td>\n",
       "      <td>2000-09-29 14:12:11 -0700</td>\n",
       "      <td>2013-02-27 15:47:29 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56892</td>\n",
       "      <td>P3</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Synaptics touchpad scrolling not working</td>\n",
       "      <td>From Bugzilla Helper:; User-Agent: Mozilla/5.0...</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>WORKSFORME</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>2000-10-16 14:48:15 -0700</td>\n",
       "      <td>2009-10-14 11:38:29 -0700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Issue_id Priority    Component  Duplicated_issue  \\\n",
       "0     10954       P3  Preferences               NaN   \n",
       "1     14871       --      General          269442.0   \n",
       "2     19118       --  Preferences               NaN   \n",
       "3     54746       P3  Preferences               NaN   \n",
       "4     56892       P3      General               NaN   \n",
       "\n",
       "                                               Title  \\\n",
       "0     Dialup properties needs to be exposed in prefs   \n",
       "1                        [Find] Find whole word only   \n",
       "2  Plug-In Manager (ui for choosing mimetype-plug...   \n",
       "3  Language encodings in font prefs dialog not so...   \n",
       "4           Synaptics touchpad scrolling not working   \n",
       "\n",
       "                                         Description    Status  Resolution  \\\n",
       "0  The dialup properties of the profile should be...  RESOLVED     WONTFIX   \n",
       "1  Please add Match Whole Word Only option to bro...  RESOLVED   DUPLICATE   \n",
       "2  I would really like a plug-in manager for my b...  RESOLVED     WONTFIX   \n",
       "3  Language encodings are listed in a seemingly r...  RESOLVED  WORKSFORME   \n",
       "4  From Bugzilla Helper:; User-Agent: Mozilla/5.0...  RESOLVED  WORKSFORME   \n",
       "\n",
       "       Version               Created_time              Resolved_time  \n",
       "0        Trunk  1999-07-30 15:55:51 -0700  2008-05-14 11:44:15 -0700  \n",
       "1        Trunk  1999-09-24 14:49:34 -0700  2011-10-05 16:35:31 -0700  \n",
       "2        Trunk  1999-11-17 14:58:26 -0800  2013-01-29 11:48:39 -0800  \n",
       "3        Trunk  2000-09-29 14:12:11 -0700  2013-02-27 15:47:29 -0800  \n",
       "4  unspecified  2000-10-16 14:48:15 -0700  2009-10-14 11:38:29 -0700  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs=bugs[bugs['Title']!=\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs['Title_Final'] = bugs['Title'].astype(str)\n",
    "type(bugs['Title_Final'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct=\"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words=[w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "stemmer = PorterStemmer()\n",
    "def word_stemmer(text):\n",
    "    stem_text = [stemmer.stem(i) for i in text]\n",
    "    return \" \".join(stem_text)\n",
    "def word_stemmer_list(text):\n",
    "    stem_text = [stemmer.stem(i) for i in text]\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs['Title_Final']= bugs['Title_Final'].apply(lambda x: remove_punctuation(x))\n",
    "bugs['Title_Final']= bugs['Title_Final'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "bugs['Title_Final']= bugs['Title_Final'].apply(lambda x: remove_stopwords(x))\n",
    "bugs['Title_Final']= bugs['Title_Final'].apply(lambda x: word_lemmatizer(x))\n",
    "bugs['Title_Final_str']= bugs['Title_Final'].apply(lambda x: word_stemmer(x))\n",
    "bugs['Title_Final_list']= bugs['Title_Final'].apply(lambda x: word_stemmer_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [dialup, properti, need, expos, pref]\n",
       "1                             [find, find, whole, word]\n",
       "2     [plugin, manag, ui, choos, mimetypeplugin, ass...\n",
       "3            [languag, encod, font, pref, dialog, sort]\n",
       "4                      [synapt, touchpad, scroll, work]\n",
       "5        [open, histori, window, select, current, site]\n",
       "6     [cooki, manag, dont, allow, site, set, remov, ...\n",
       "7             [today, histori, folder, expand, default]\n",
       "8           [search, bookmark, access, manag, bookmark]\n",
       "9                                    [bookmark, option]\n",
       "10    [fixnot, correctli, retriev, post, data, save,...\n",
       "11    [show, uri, statu, bar, onmouseov, backforward...\n",
       "12    [local, problem, bookmark, sort, menu, histori...\n",
       "13           [ui, allow, extern, handler, intern, type]\n",
       "14              [mozilla, support, x11, session, manag]\n",
       "15    [post, result, page, appear, global, histori, ...\n",
       "16    [nonrespond, window, unc, share, hang, bookmar...\n",
       "17                                [want, infinit, back]\n",
       "18             [use, favicon, webpag, shortcut, window]\n",
       "19                   [flicker, icon, url, locat, field]\n",
       "Name: Title_Final_list, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs['Title_Final_list'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Skip Gram model \n",
    "model = Word2Vec(bugs['Title_Final_list'], min_count = 1,  \n",
    "                 size = 100, window = 5, sg=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)\n",
    "\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list=[]\n",
    "for entry in bugs['Title_Final_list']:\n",
    "    if has_vector_representation(model.wv, entry):\n",
    "        vec_list.append(document_vector(model.wv, entry))\n",
    "    else:\n",
    "        vec_list.append(np.zeros((1,100)))\n",
    "bugs[\"vector\"] = vec_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [0.19635367, -0.40720612, 0.21212259, -0.26033...\n",
       "1         [0.029688686, -0.3410546, 0.005252581, -0.1907...\n",
       "2         [0.022631804, -0.47908512, 0.30088642, -0.0549...\n",
       "3         [-0.09969988, -0.42498899, 0.3972689, -0.46974...\n",
       "4         [-0.09777178, -0.21430232, 0.1890018, -0.14790...\n",
       "                                ...                        \n",
       "115809    [0.0042911144, -0.46271554, 0.23828256, -0.083...\n",
       "115810    [-0.03614329, -0.3751416, 0.24071841, -0.09389...\n",
       "115811    [0.13700095, -0.5042338, 0.12149227, 0.0558527...\n",
       "115812    [0.29436627, -0.3476808, 0.09904309, -0.041370...\n",
       "115813    [0.050985843, -0.263279, 0.23332639, 0.0947749...\n",
       "Name: vector, Length: 115798, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azmi/Projects/Duplicate Bug Detection/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float32 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c50d678df3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbugs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Duplicate Bug Detection/venv/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                 )\n\u001b[0;32m-> 1447\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Duplicate Bug Detection/venv/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \"\"\"\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Duplicate Bug Detection/venv/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# compute the weighted average of all words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mall_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float32 object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55074215"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"result\",\"icon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
